{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries, \"importing\" data sets and setting storage\n",
    "\n",
    "In a working situation there would be 1000s of schemes, domains and safe names that could be imported here. I have just taken the example of a few banks for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "#########\n",
    "# Look Up Matricies - obviously replacable with a csv etc, that has more entires\n",
    "#########\n",
    "scheme = [\"https://\", \"mailto://\", \"ftp://\"]\n",
    "top_level_domain = [\".com\", \".fi\", \".co.uk\", \".edu\", \".org\"]\n",
    "\n",
    "#########\n",
    "# Look Up dintionary - again obviously replacable with a csv etc, that has more entires\n",
    "#########\n",
    "safe_name = {\"DanskeBank\": \"danskebank\", \"OP\": \"op\", \"Nordea\": \"nordea\", \"Aktia\": \"aktia\"}\n",
    "\n",
    "#########\n",
    "#Storage system\n",
    "#########\n",
    "\n",
    "strange_features_index = {}\n",
    "gateway_characters_index = {}\n",
    "url_info = {}\n",
    "url_sim_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating functions to then impliment in my final function\n",
    "\n",
    "The functions are in three general themes\n",
    "1. Seperating the first free url (https://arxiv.org/pdf/1510.06501.pdf) - this can be changed to seperate any part of the url, I was simply following the beginning of the article above\n",
    "\n",
    "2. Checking a url for similarities to a known one\n",
    "\n",
    "3. Checking a url for strange features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "#Remove the first free url from a url\n",
    "########\n",
    "\n",
    "# Removes the scheme, by deleting it from the url\n",
    "def scheme_splicer(url):\n",
    "    #Remove scheme\n",
    "    for sche in scheme:\n",
    "        if (url.find(sche) != -1):\n",
    "            url = url[len(sche):]\n",
    "            return url\n",
    "\n",
    "# Removes the end, after the domain by deleting any values after the url\n",
    "def top_level_domain_splicer(url):\n",
    "    for tld in top_level_domain:\n",
    "        if (url.find(tld) != -1):\n",
    "            url = url[:url.find(tld)]\n",
    "            return url\n",
    "        #### This will cut out things that start wuth .fi like finance\n",
    "\n",
    "# Combines the previous two\n",
    "def url_splicer(url):\n",
    "    if scheme_splicer(url) != None:\n",
    "        url_no_scheme = scheme_splicer(url)\n",
    "    else:\n",
    "        url_no_scheme = url\n",
    "        # as there is a finite list of possible scheme this should only happen if here is not a scheme in the first place\n",
    "        # Or a typo\n",
    "    if top_level_domain_splicer(url_no_scheme) != None:\n",
    "        free_url = top_level_domain_splicer(url_no_scheme)\n",
    "    else:\n",
    "        free_url = url_no_scheme\n",
    "        #This again, should work as there is also a finite numner of top level domains\n",
    "        #If there is no top level domain caught there was none in the first place\n",
    "        #Although a more extensive list is needed than the one I have above\n",
    "    return free_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "#Name Reference\n",
    "#############\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "    # This finds the similar characters in strings and trandforms them into ratios\n",
    "    # Critisism - this is position based, could be improved with caracter and position comparason\n",
    "\n",
    "#printing a string with the official website if so\n",
    "def name_checker(url):\n",
    "    url = url_splicer(url)\n",
    "    for website in safe_name:\n",
    "        #Find if website has the same first url\n",
    "        if ((similar(url, safe_name[website]) == 1) == True):\n",
    "            return \"Offical Url (first free): {web}\".format(web = website)\n",
    "        #if not ture then how similar are the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "#Checking the url for strnage features\n",
    "###########\n",
    "\n",
    "#This function prints off a dictionary of the number of each feature\n",
    "def strange_featrues(url):\n",
    "    #Safe characters for urls (check these)\n",
    "    strange_features_index['dot'] = url.count('.')\n",
    "    strange_features_index['dollar'] = url.count('$')\n",
    "    strange_features_index['plus'] = url.count('+')\n",
    "    strange_features_index['apostrophe'] = url.count('\\'')\n",
    "    strange_features_index['dash'] = url.count('-')\n",
    "    strange_features_index['semicolon'] = url.count(';')\n",
    "    strange_features_index['colon'] = url.count(':')\n",
    "    strange_features_index['comma'] = url.count(',')\n",
    "    strange_features_index['slash'] = url.count('/')\n",
    "    strange_features_index['question_mark'] = url.count('?')\n",
    "    strange_features_index['at'] = url.count('@')\n",
    "    strange_features_index['equals'] = url.count('=')\n",
    "    strange_features_index['and'] = url.count('&')\n",
    "    return strange_features_index\n",
    "    \n",
    "    \n",
    "#This function prints off a dictionary of the number of each gateway feature\n",
    "def gateway_featrues(url):\n",
    "    #Gateway modifiable characters, these are places that the phisher could take you away from the original website\n",
    "    gateway_characters_index['o_curley_bracket'] = url.count(\"{\")\n",
    "    gateway_characters_index['c_curley_bracket']  = url.count(\"}\")\n",
    "    gateway_characters_index['o_square_bracket']  = url.count(\"[\")\n",
    "    gateway_characters_index['c_square_bracket']  = url.count(\"]\")\n",
    "    gateway_characters_index['tilde'] = url.count(\"~\")\n",
    "    gateway_characters_index['^'] = url.count(\"^\")\n",
    "    gateway_characters_index['line'] = url.count(\"|\")\n",
    "    return gateway_characters_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Final Function\n",
    "\n",
    "This function takes all of the other functions information and complies them into a dictionary labled with the original url ready for later diagnosis. I have only gathered esthetic features here, it would be nice to also get the age of the url, amounts of views (possition in a google search) etc. but the method would be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "#Final Function\n",
    "#######\n",
    "def url_checker(url):\n",
    "    # Adds the url to the dictionary as the key\n",
    "    url_info[url]={}\n",
    "    safe_names = safe_name\n",
    "    #Update the domain \n",
    "    if (name_checker(url) != None):\n",
    "        url_info[url][\"Domain_Analysis\"] = name_checker(url)\n",
    "        url_info[url][\"Similarity_Index\"] = \"NA\"\n",
    "    else: \n",
    "        url_info[url][\"Domain_Analysis\"] = \"Unofficial\"\n",
    "        safe_names = safe_name # to protect my original data, just in case\n",
    "        for name in safe_names:\n",
    "            url_sim_info[name] = similar(url, safe_names[name])\n",
    "            url_info[url][\"Similarity_Index\"] = url_sim_info\n",
    "            \n",
    "    #Check Unusual Features\n",
    "    url_info[url][\"Length\"] = len(url)\n",
    "    url_info[url][\"Strange_Features\"] = strange_featrues(url)\n",
    "    url_info[url][\"Gateway_Features\"] = gateway_featrues(url)\n",
    "    \n",
    "    return url_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Function and Result Presentation\n",
    "\n",
    "Although having a presentation in the code itself is not that useful, I though that seeing the dictionary as an output was dificult to analyse immediately and thus difficult to see what my code produces. Although in reality you would then run more functions on this url so would not present it at this stage and present it in a much better way - in terms of the task it adds clarity. Dictionaries are an easily idexable storgae stsyem in the code with easy updates (these are the main reason I used them), however they are not easly to read by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(url):\n",
    "    print(\"\"\"{url}\n",
    "    \\t Domain Analysis: {da}\n",
    "    \\t Similarity Index: {si}\n",
    "    \\t Length: {l}\n",
    "    \\t Strange Features:\n",
    "    Dollar: {d} \\t Plus: {p} \\t Apostrophe: {ap} \\t Dash: {d2} \\t Semicolon: {s} \\t Colon: {sc} \\t Comma: {co} \\t Slash: {sl} \\t Question Mark: {qm} \\t At: {at} \\t Equals: {eq} \\t And: {a}\n",
    "    \\t Gateway Features:\n",
    "    Open Curley Bracket: {ocb} \\t Closed Curley Bracket: {ccb} \\t Open Square Brackets: {osb} \\t Closed Square Brackets: {csb} \\t Tilde: {td} \\t Hat: {hat} \\t Line: {line}\n",
    "    \"\"\".format(si = url_info[url][\"Similarity_Index\"], url = url, l = url_info[url][\"Length\"], d = url_info[url][\"Strange_Features\"][\"dollar\"], p = url_info[url][\"Strange_Features\"][\"plus\"], ap = url_info[url][\"Strange_Features\"][\"apostrophe\"], d2 = url_info[url][\"Strange_Features\"][\"dash\"], s = url_info[url][\"Strange_Features\"][\"semicolon\"], sc = url_info[url][\"Strange_Features\"][\"colon\"], co = url_info[url][\"Strange_Features\"][\"comma\"], sl = url_info[url][\"Strange_Features\"][\"slash\"], qm = url_info[url][\"Strange_Features\"][\"question_mark\"], at = url_info[url][\"Strange_Features\"][\"at\"], eq = url_info[url][\"Strange_Features\"][\"equals\"], a = url_info[url][\"Strange_Features\"][\"and\"], ocb = url_info[url][\"Gateway_Features\"][\"o_curley_bracket\"], ccb = url_info[url][\"Gateway_Features\"][\"c_curley_bracket\"], osb = url_info[url][\"Gateway_Features\"][\"o_square_bracket\"], csb = url_info[url][\"Gateway_Features\"][\"c_square_bracket\"], td = url_info[url][\"Gateway_Features\"][\"tilde\"], hat = url_info[url][\"Gateway_Features\"][\"^\"], line = url_info[url][\"Gateway_Features\"][\"line\"], da = url_info[url][\"Domain_Analysis\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://op.fi/this.is.not.a.scam\n",
      "    \t Domain Analysis: Offical Url (first free): OP\n",
      "    \t Similarity Index: NA\n",
      "    \t Length: 32\n",
      "    \t Strange Features:\n",
      "    Dollar: 0 \t Plus: 0 \t Apostrophe: 0 \t Dash: 0 \t Semicolon: 0 \t Colon: 1 \t Comma: 0 \t Slash: 3 \t Question Mark: 0 \t At: 0 \t Equals: 0 \t And: 0\n",
      "    \t Gateway Features:\n",
      "    Open Curley Bracket: 0 \t Closed Curley Bracket: 0 \t Open Square Brackets: 0 \t Closed Square Brackets: 0 \t Tilde: 0 \t Hat: 0 \t Line: 0\n",
      "    \n",
      "https://o.p.fi/this.is.a.#scam\n",
      "    \t Domain Analysis: Unofficial\n",
      "    \t Similarity Index: {'DanskeBank': 0.1, 'OP': 0.0625, 'Nordea': 0.1111111111111111, 'Aktia': 0.17142857142857143}\n",
      "    \t Length: 30\n",
      "    \t Strange Features:\n",
      "    Dollar: 0 \t Plus: 0 \t Apostrophe: 0 \t Dash: 0 \t Semicolon: 0 \t Colon: 1 \t Comma: 0 \t Slash: 3 \t Question Mark: 0 \t At: 0 \t Equals: 0 \t And: 0\n",
      "    \t Gateway Features:\n",
      "    Open Curley Bracket: 0 \t Closed Curley Bracket: 0 \t Open Square Brackets: 0 \t Closed Square Brackets: 0 \t Tilde: 0 \t Hat: 0 \t Line: 0\n",
      "    \n",
      "ftp://n.o#r@d-e$a.fi\n",
      "    \t Domain Analysis: Unofficial\n",
      "    \t Similarity Index: {'DanskeBank': 0.2, 'OP': 0.09090909090909091, 'Nordea': 0.46153846153846156, 'Aktia': 0.16}\n",
      "    \t Length: 20\n",
      "    \t Strange Features:\n",
      "    Dollar: 1 \t Plus: 0 \t Apostrophe: 0 \t Dash: 1 \t Semicolon: 0 \t Colon: 1 \t Comma: 0 \t Slash: 2 \t Question Mark: 0 \t At: 1 \t Equals: 0 \t And: 0\n",
      "    \t Gateway Features:\n",
      "    Open Curley Bracket: 0 \t Closed Curley Bracket: 0 \t Open Square Brackets: 0 \t Closed Square Brackets: 0 \t Tilde: 0 \t Hat: 0 \t Line: 0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "lst = [\"https://op.fi/this.is.not.a.scam\", \"https://o.p.fi/this.is.a.#scam\", \"ftp://n.o#r@d-e$a.fi\"]\n",
    "\n",
    "for url in lst:\n",
    "    url_checker(url)\n",
    "    print_results(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
